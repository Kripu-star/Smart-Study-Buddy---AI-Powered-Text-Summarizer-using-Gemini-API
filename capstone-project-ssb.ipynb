{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11465399,"sourceType":"datasetVersion","datasetId":7184813}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Capstone Project\n[**Gen AI Intensive 2025Q1**](https://www.kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1)\n\n\n*By Pushpam Kumari*","metadata":{}},{"cell_type":"markdown","source":"[](https://www.kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1)","metadata":{}},{"cell_type":"markdown","source":"## üìò Project Title\n ## Smart Study Buddy ‚Äì Gen AI Learning Assistant using Gemini API\n An AI-Powered Personalized Learning Assistant using Gemini API!\n","metadata":{}},{"cell_type":"markdown","source":"## üß† Problem Statement\nStudents often find it difficult to digest lengthy chapters, revise effectively before exams, or get quick help with understanding complex concepts. Traditional learning resources don't always offer personalized explanations or tailored practice questions. This leads to wasted time, low retention, and academic stress.\n\n","metadata":{}},{"cell_type":"markdown","source":"## üéØ Use Case","metadata":{}},{"cell_type":"markdown","source":"# üìö‚ú® Smart Study Buddy ‚Äì Gen AI Learning Assistant using Gemini API\n\nThis notebook showcases a Gen AI-powered personalized learning assistant designed to help students:\n\n- üìñ Summarize study material and long chapters  \n- üí° Explain tough concepts in a simple way  \n- ‚ùì Generate quiz questions for practice and revision  \n\nBuilt using Google‚Äôs Gemini model via the Python SDK, this project demonstrates multiple Gen AI capabilities working together to solve real academic challenges.  \nWith features like summarization, question-answering, and quiz generation, it acts like a smart tutor tailored to the learner's needs.\nThis tool acts like a digital tutor, available 24/7, to make studying more efficient, personalized, and interactive ‚Äî especially during last-minute revisions or when preparing for exams.\n","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Setup and Installation","metadata":{}},{"cell_type":"markdown","source":"The following cells install and configure the required libraries and APIs to use the Google Generative AI SDK.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:35:56.327820Z","iopub.execute_input":"2025-04-19T11:35:56.328256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -qy jupyterlab # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\" \"chromadb==0.6.3\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\n\nfrom IPython.display import HTML, Markdown, display\ngenai.__version__","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.api_core import retry\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.generativeai import configure, GenerativeModel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß† GenAI Capabilities Used","metadata":{}},{"cell_type":"markdown","source":"### ‚ú® Capability 1:Text Generation (Summarization)\n* What it does: Takes a long piece of text and generates a concise summary based on the content.\n\n* How I used it: I gave the Gemini model a paragraph (news article), and it generated a summary using generate_content().","metadata":{}},{"cell_type":"markdown","source":"## üõ†Ô∏è Implementation\n\nWe will pass a custom prompt to the Gemini model asking it to summarize a paragraph. Here's an example.\n","metadata":{}},{"cell_type":"code","source":"paragraph = \"\"\"\nToday, Kapil Sibal, Senior Advocate and President of the Supreme Court Bar Association, addressed a press conference on the Vice President of India, Jagdeep Dhankhars remarks that the Supreme Court was using Article 142 as a nuclear missile against democratic forces.\n\nSibal said he is deeply saddened that a constitutional functionary is making such remarks.\n\n\"When I woke up this morning and read the Vice Presidents remarks in newspapers, I felt deeply saddened and shocked. If there is one institution even today which the people trust, it is the judicial institutions, be it the Supreme Court or the High Courts. Its truly concerning how some government officials respond to judicial decisions, when the verdict suits them, for instance, Article 370 abrogation or the Ram Janbhoomi judgment, they cite it as the Supreme Courts wisdom. But the moment a judgment doesnot align with their views, for instance, the recent Justice Pardiwalas judgment, they start levelling accusations.\"\n\"\"\"\n\nsummary_prompt = f\"Summarize the following paragraph:\\n\\n{paragraph}\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=summary_prompt\n)\n\nprint(\"üîç Summary:\\n\", response.text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üì§ Output\n\nThe model generates a short summary of the given text using its generative capabilities.\n\n## üìñ Explanation\n\nThe `generate_content()` method is used to pass a summarization prompt to the model. The model processes the input and returns a concise version of the paragraph, demonstrating the ability to understand and condense content contextually.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### ‚ú® Capability 2: Semantic Understanding + Q&A (RAG-style\n\nIn this section, we demonstrate how Gemini can understand a given article and respond to questions based on it. \nThis capability is useful for extracting insights from news content or any long-form documents using the \n`generate_content()` method of the Gemini API. This mirrors the *Retrieval-Augmented Generation (RAG)* \nconcept where questions are answered using reference material.\n","metadata":{}},{"cell_type":"markdown","source":"## üõ†Ô∏è Implementation\nWe will pass a custom prompt to the Gemini model asking it to answer the user's question. Here's an example.","metadata":{}},{"cell_type":"code","source":"question = \"What did Kapil Sibal say about the judiciary in response to the Vice President's remarks?\"\n\nprompt = f\"\"\"\nYou are a helpful assistant that uses the passage below to answer the user's question.\nOnly use the content from the passage to answer the question. If the information is not present, say so.\n\nPASSAGE:\n{paragraph}\n\nQUESTION:\n{question}\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt\n)\n\nprint(\"üß† Answer:\\n\", response.text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üì§ Output\n\nThe model generates an answer of the given query using its generative capabilities.\n\n## üìñ Explanation\n\nThe `generate_content()` method is used to pass a summarization prompt to the model. The model processes the input and returns a concise version of the paragraph, demonstrating the ability to understand and condense content contextually.\n","metadata":{}},{"cell_type":"markdown","source":"### ‚ú® Capability 3:Structured Output with JSON\nIn this section, we use Gemini to generate multiple-choice questions (MCQs) based on a provided paragraph. We also instruct the model to format the output in JSON so that it can be easily parsed or integrated into educational apps and platforms.\n\nStructured outputs are useful when building systems that need to programmatically use the output ‚Äî such as a quiz app or LMS (Learning Management System).\n","metadata":{}},{"cell_type":"markdown","source":"\n## üõ†Ô∏è Implementation\nWe will pass a custom prompt to the Gemini model asking it to answer the user's question. Here's an example.","metadata":{}},{"cell_type":"code","source":"\n\nquiz_prompt = f\"\"\"\nGenerate 4 multiple-choice quiz questions based on the passage below.\nEach question should have:\n- A \"question\" field (string)\n- An \"options\" field (list of 4 strings)\n- A \"correct_option\" field (one of \"A\", \"B\", \"C\", or \"D\")\n\nRespond in JSON format only.\n\npassage:{paragraph}\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=quiz_prompt\n)\n\n##print(response.text)\nMarkdown(response.text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üì§ Output\nThe Gemini model generates a short quiz in a structured format based on the input paragraph. Each question is relevant to the content, allowing learners to quickly test their understanding.\n\n## üìñ Explanation\nThis section demonstrates the **Quiz Generation** capability of Gemini. By using the `generate_content()` method with a customized prompt, the model extracts key ideas from the input text and transforms them into **multiple-choice questions**.\n\nSuch a feature is highly beneficial for:\n\n- **Students** who want quick revision tools  \n- **Teachers** looking to generate quizzes from their study material  \n- **EdTech apps** that aim to personalize learning experiences\n\nAdditionally, we formatted the output in Markdown to ensure the questions are displayed cleanly and are easy to read, making the tool more user-friendly and practical for real-world educational use cases.\n","metadata":{}},{"cell_type":"markdown","source":"## ‚úÖ Conclusion\n\nIn this project, we built a simple yet powerful tool for students using Google‚Äôs Gemini model.  \nBy leveraging multiple Gen AI capabilities ‚Äî summarization, question-answering, and quiz generation ‚Äî we created a personalized learning assistant that makes studying more efficient and engaging.\n\nThis project not only demonstrates the practical applications of Generative AI in education but also opens up possibilities for further innovation, such as integrating with web platforms or expanding to other types of learning content.\n\nGenerative AI has the potential to become a student's best companion ‚Äî and this is just the beginning.\n","metadata":{}},{"cell_type":"markdown","source":"## üîÆ Future Scope\n- Enhance the tool to accept inputs from various sources such as **PDFs, Word documents, or YouTube video transcripts** for broader usability.\n- Leverage additional Gemini capabilities such as **embeddings** for document retrieval or **multi-turn chat** for more interactive Q&A sessions.\n- Integrate the solution into a simple and intuitive **web application** using frameworks like **Flask** or **Streamlit** to make it accessible to users without technical knowledge.","metadata":{}}]}